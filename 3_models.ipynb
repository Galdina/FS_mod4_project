{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file path for x-ray\n",
    "#----------\n",
    "# all files \n",
    "folder_path = 'data/'\n",
    "# we have three folders for images dataset\n",
    "set_list = ['train','test','val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace file path for x-ray after research\n",
    "test_folder = folder_path + 'val' #YOTO\n",
    "train_folder = folder_path + 'train'\n",
    "val_folder = folder_path + 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Fitting\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale         = 1./255,\n",
    "                    shear_range     = 0.2,\n",
    "                    zoom_range      = 0.2,\n",
    "                    rotation_range  = 10,\n",
    "                    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    train_folder,  \n",
    "                    target_size   = (224, 224),  \n",
    "                    batch_size    = 16,\n",
    "                    classes=['pneumonia','normal'])\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                    val_folder, \n",
    "                    target_size = (224, 224), \n",
    "                    batch_size  = 624, \n",
    "                    classes=['pneumonia','normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 173056)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                11075648  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 11,132,098\n",
      "Trainable params: 11,132,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "326/326 - 339s - loss: 0.4990 - accuracy: 0.8140 - val_loss: 0.5709 - val_accuracy: 0.7660\n",
      "Epoch 2/5\n",
      "326/326 - 362s - loss: 0.2828 - accuracy: 0.8924 - val_loss: 0.4294 - val_accuracy: 0.8429\n",
      "Epoch 3/5\n",
      "326/326 - 383s - loss: 0.2569 - accuracy: 0.9089 - val_loss: 0.3882 - val_accuracy: 0.8365\n",
      "Epoch 4/5\n",
      "326/326 - 346s - loss: 0.2287 - accuracy: 0.9176 - val_loss: 0.8784 - val_accuracy: 0.7051\n",
      "Epoch 5/5\n",
      "326/326 - 352s - loss: 0.2072 - accuracy: 0.9256 - val_loss: 0.3568 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb582043b90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_generator, validation_data=validation_generator, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took a total of 0:30:12.879777\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=test_folder,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        classes=['pneumonia','normal'])\n",
    "\n",
    "predictions = cnn.predict(x=test_generator, steps = 1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_regularizer = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(0.01), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                12845120  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 12,901,570\n",
      "Trainable params: 12,901,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_regularizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_regularizer.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 - 333s - loss: 0.3798 - accuracy: 0.7429 - val_loss: 0.5554 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "326/326 - 347s - loss: 0.4115 - accuracy: 0.7429 - val_loss: 3.4988 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "326/326 - 317s - loss: 0.3175 - accuracy: 0.8370 - val_loss: 0.4771 - val_accuracy: 0.8638\n",
      "Epoch 4/10\n",
      "326/326 - 357s - loss: 0.2473 - accuracy: 0.9110 - val_loss: 0.5296 - val_accuracy: 0.8478\n",
      "Epoch 5/10\n",
      "326/326 - 329s - loss: 0.2226 - accuracy: 0.9176 - val_loss: 0.4441 - val_accuracy: 0.8446\n",
      "Epoch 6/10\n",
      "326/326 - 315s - loss: 0.2183 - accuracy: 0.9252 - val_loss: 0.3097 - val_accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "326/326 - 314s - loss: 0.1983 - accuracy: 0.9314 - val_loss: 0.4357 - val_accuracy: 0.8413\n",
      "Epoch 8/10\n",
      "326/326 - 317s - loss: 0.1898 - accuracy: 0.9337 - val_loss: 0.5279 - val_accuracy: 0.8526\n",
      "Epoch 9/10\n",
      "326/326 - 312s - loss: 0.1910 - accuracy: 0.9369 - val_loss: 0.3511 - val_accuracy: 0.8862\n",
      "Epoch 10/10\n",
      "326/326 - 319s - loss: 0.1819 - accuracy: 0.9410 - val_loss: 0.3433 - val_accuracy: 0.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5030a55d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_regularizer.fit(x=train_generator, validation_data=validation_generator, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took a total of 0:54:45.045793\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dropout = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(0.01), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                25690176  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 25,783,554\n",
      "Trainable params: 25,783,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dropout.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 - 404s - loss: 0.6612 - accuracy: 0.7895 - val_loss: 0.6147 - val_accuracy: 0.7869\n",
      "Epoch 2/10\n",
      "326/326 - 399s - loss: 0.3194 - accuracy: 0.8905 - val_loss: 0.4636 - val_accuracy: 0.8221\n",
      "Epoch 3/10\n",
      "326/326 - 417s - loss: 0.2754 - accuracy: 0.9062 - val_loss: 0.3965 - val_accuracy: 0.8638\n",
      "Epoch 4/10\n",
      "326/326 - 398s - loss: 0.2419 - accuracy: 0.9179 - val_loss: 0.5731 - val_accuracy: 0.8622\n",
      "Epoch 5/10\n",
      "326/326 - 405s - loss: 0.2248 - accuracy: 0.9264 - val_loss: 0.7073 - val_accuracy: 0.8013\n",
      "Epoch 6/10\n",
      "326/326 - 408s - loss: 0.2332 - accuracy: 0.9285 - val_loss: 0.5023 - val_accuracy: 0.8397\n",
      "Epoch 7/10\n",
      "326/326 - 417s - loss: 0.2174 - accuracy: 0.9248 - val_loss: 0.3939 - val_accuracy: 0.8910\n",
      "Epoch 8/10\n",
      "326/326 - 414s - loss: 0.2038 - accuracy: 0.9294 - val_loss: 0.6159 - val_accuracy: 0.8510\n",
      "Epoch 9/10\n",
      "326/326 - 464s - loss: 0.1975 - accuracy: 0.9331 - val_loss: 0.3547 - val_accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "326/326 - 397s - loss: 0.1911 - accuracy: 0.9339 - val_loss: 0.4408 - val_accuracy: 0.8638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5035b6450>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_dropout.fit(x=train_generator, validation_data=validation_generator, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took a total of 1:09:23.335437\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_softmax = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(0.01), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                25690176  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 25,783,554\n",
      "Trainable params: 25,783,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_softmax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_softmax.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "326/326 - 393s - loss: 0.8777 - accuracy: 0.8092 - val_loss: 0.6705 - val_accuracy: 0.8381\n",
      "Epoch 2/5\n",
      "326/326 - 452s - loss: 0.4359 - accuracy: 0.8959 - val_loss: 0.6030 - val_accuracy: 0.8429\n",
      "Epoch 3/5\n",
      "326/326 - 363s - loss: 0.3295 - accuracy: 0.9112 - val_loss: 0.5705 - val_accuracy: 0.8429\n",
      "Epoch 4/5\n",
      "326/326 - 416s - loss: 0.2860 - accuracy: 0.9214 - val_loss: 0.5708 - val_accuracy: 0.8429\n",
      "Epoch 5/5\n",
      "326/326 - 374s - loss: 0.2553 - accuracy: 0.9241 - val_loss: 0.6708 - val_accuracy: 0.7949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4d459c310>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_softmax.fit(x=train_generator, validation_data=validation_generator, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took a total of 0:34:16.528241\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmsprop = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(224, 224, 3), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(0.01), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                6422592   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,525,218\n",
      "Trainable params: 6,525,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_rmsprop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmsprop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_start = datetime.datetime.now()\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 - 291s - loss: 1.0794 - accuracy: 0.7569 - val_loss: 0.7757 - val_accuracy: 0.7228\n",
      "Epoch 2/10\n",
      "326/326 - 289s - loss: 0.4144 - accuracy: 0.8763 - val_loss: 1.1578 - val_accuracy: 0.6490\n",
      "Epoch 3/10\n",
      "326/326 - 313s - loss: 0.3574 - accuracy: 0.8913 - val_loss: 0.4326 - val_accuracy: 0.8734\n",
      "Epoch 4/10\n",
      "326/326 - 306s - loss: 0.2890 - accuracy: 0.9087 - val_loss: 1.0251 - val_accuracy: 0.7147\n",
      "Epoch 5/10\n",
      "326/326 - 309s - loss: 0.2619 - accuracy: 0.9153 - val_loss: 0.6399 - val_accuracy: 0.7724\n",
      "Epoch 6/10\n",
      "326/326 - 336s - loss: 0.2432 - accuracy: 0.9264 - val_loss: 0.4631 - val_accuracy: 0.8766\n",
      "Epoch 7/10\n",
      "326/326 - 300s - loss: 0.2361 - accuracy: 0.9202 - val_loss: 0.6563 - val_accuracy: 0.8381\n",
      "Epoch 8/10\n",
      "326/326 - 341s - loss: 0.2211 - accuracy: 0.9279 - val_loss: 0.4824 - val_accuracy: 0.8734\n",
      "Epoch 9/10\n",
      "326/326 - 343s - loss: 0.2172 - accuracy: 0.9331 - val_loss: 0.3356 - val_accuracy: 0.8862\n",
      "Epoch 10/10\n",
      "326/326 - 316s - loss: 0.2133 - accuracy: 0.9331 - val_loss: 0.5206 - val_accuracy: 0.8654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb4d45ec710>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_rmsprop.fit(x=train_generator, validation_data=validation_generator, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took a total of 0:53:00.993460\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training took a total of {}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[297  93]\n",
      " [159  75]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = cnn_rmsprop.predict(x=validation_generator, steps = 1, verbose=0)\n",
    "cm = confusion_matrix(y_true=validation_generator.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "\n",
    "cm_plot_labels = ['pneumonia','normal']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.76      0.70       390\n",
      "           1       0.45      0.32      0.37       234\n",
      "\n",
      "    accuracy                           0.60       624\n",
      "   macro avg       0.55      0.54      0.54       624\n",
      "weighted avg       0.57      0.60      0.58       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_generator.classes, np.argmax(predictions, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
